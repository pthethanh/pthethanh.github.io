<!DOCTYPE html><html domain=thefortunedays.com lang=en><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><link href="/img/favicon/favicon-192x192.png?hash=735479e2c4" rel=icon type=image/png><meta content=#ff577d name=theme-color><meta content="max-snippet:-1, max-image-preview: large, max-video-preview: -1" name=robots><title>Apache Spark Structured Streaming</title><meta content="Apache Spark Structured Streaming" property=og:title><meta content="Getting started with Apache Spark and Structure Streaming on Kubernetes." name=description><meta content="Getting started with Apache Spark and Structure Streaming on Kubernetes." property=og:description><meta content=summary_large_image name=twitter:card><meta content=@phamthethanh108 name=twitter:site><meta content=@phamthethanh108 name=twitter:creator><meta content=https://thefortunedays.com/img/remote/Z1o6V9l.jpg property=og:image><link href=https://thefortunedays.com/articles/getting-started-with-apache-spark-structured-streaming-kafka-postgresql/ rel=canonical><meta content=no-referrer-when-downgrade name=referrer><link href=/feed/feed.xml rel=alternate type=application/atom+xml title="The Fortune Days"><link href=/ rel=preconnect crossorigin=""><link href=https://fonts.googleapis.com rel=preconnect><link href=https://fonts.gstatic.com rel=preconnect crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Coustard:wght@400;900&family=Lora:ital,wght@0,400..700;1,400..700&family=Montserrat:ital,wght@0,100..900;1,100..900&family=UnifrakturMaguntia&display=swap" rel=stylesheet><script async src="/js/min.js?hash=8db32dcb3a" data-cwv-src="/js/web-vitals.js?hash=a2ed2205a4" defer></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-9X9G2YCR2X"></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', 'G-9X9G2YCR2X');</script><script csp-hash="">if (/Mac OS X/.test(navigator.userAgent))document.documentElement.classList.add('apple')</script><style>@keyframes neon-blink{44%,46%,98%,to{opacity:1}45%{opacity:.7}99%{opacity:.5}}:root{--primary: black;--primary-dark: black;--text-color: black;--bg-color: white;--nav-bg-color: #fff;--nav-text-color: black;--reading-progress: lightgray;--footer-bg-color: white;--footer-text-color: black;--code-bg: #e2777a;--code: #2d2d2d;--mark: #f9c412;--hr: black;--figcaption: #ccc;--heading-color: black;--post-date: rgb(56, 54, 54);--post-separator: rgb(56, 54, 54);--font-family: 'Lora', sans-serif;--main-width: calc(100vw - 3em)
}main img{content-visibility:auto}article *{scroll-margin-top:50px}header{z-index:1;display:flex;flex-direction:column;align-items:center;padding-top:2em;padding-bottom:2em}@media (min-width:37.5em){:root{--main-width: calc(37.5em - 3em)
  }}html{line-height:1.15;-webkit-text-size-adjust:100%;font-size:14px;color:var(--text-color);background-color:var(--bg-color);text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased}body{margin:0}@media (min-width:320px){html{font-size:14px}}@media (min-width:480px){html{font-size:14px}}@media (min-width:600px){html{font-size:14px}}@media (min-width:801px){html{font-size:14px}}@media (min-width:1025px){html{font-size:16px}}@media (min-width:1281px){html{font-size:16px}}dialog,share-widget{position:fixed;opacity:.9}share-widget{right:20px;bottom:20px}.apple share-widget div{background-image:url(/img/share-apple.svg)}dialog{background-color:#0a9cf5;z-index:1000;border:.2rem solid #fff;border-radius:1.25rem;padding:1.25em}img[align=left]{width:auto;height:16rem;margin-right:1rem;margin-bottom:1rem}dl{clear:both;display:block!important;margin:0 0 1.5em}#posts li{margin-bottom:.5em}hr{box-sizing:content-box;height:0;overflow:visible;border-bottom:1px solid var(--hr)}pre,samp{font-size:1em}samp{font-family:monospace,monospace}a{background-color:transparent;color:#f9c412;text-decoration:none;color:var(--primary)}abbr[title]{border-bottom:0;text-decoration:underline dotted}b,strong{font-weight:700}small{font-size:80%;color:#ccc}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15}input,optgroup,select,textarea{margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}legend{color:inherit;display:table;max-width:100%;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio],legend{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden],template{display:none}h1,h2,h3,h4,h5{margin:3rem 0 1.38rem;line-height:1.3;font-weight:400}h1{font-size:2.074rem}h2{font-size:1.728rem}h3{font-size:1.44rem}h4{font-size:1.2rem}h5{font-size:1rem}body,ol,p,pre,ul{font-size:1rem;line-height:1.6}ol,p,pre,ul{margin-bottom:1.36rem}dt,th{font-weight:600}td,th{border-bottom:1px solid #595959;overflow:auto;padding:.75em;text-align:left;vertical-align:top}thead th{border-bottom:1px solid #f9c412}table{display:table}code,pre,table{overflow-x:auto}pre{font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace}pre:has(code:not([class])){background:#2d2d2d}pre code:not([class]){color:#ccc;padding:0;overflow-x:scroll}code,kbd,mark{padding:0 .3em}code,kbd{border-radius:.3em;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:90%;background:var(--code-bg);color:var(--code)}mark{background:var(--mark)}h1,h2{font-family:"Coustard"}a:hover{text-decoration:underline}figcaption{color:var(--figcaption);margin-top:.75em;font-size:80%}@media (max-width:767px){fieldset{min-width:0}fieldset *{flex-grow:1;page-break-before:auto}x:-moz-any-link{display:table-cell}}html{font-family:var(--font-family)}form{padding:1.5em 1.5em 0;border:.2rem solid #202020}form small{font-style:italic}fieldset{padding:0;margin:0}fieldset legend{font-size:150%;margin-bottom:.75em}button,input,select,textarea{border-radius:.3em;max-width:100%}input{padding:.75em}textarea{display:inline-block}button+input[type=checkbox],button+input[type=radio],button+label,input+input[type=checkbox],input+input[type=radio],input+label,label+*,select+input[type=checkbox],select+input[type=radio],select+label,textarea+input[type=checkbox],textarea+input[type=radio],textarea+label{page-break-before:always}form,input,select,textarea{margin-bottom:1.5em}textarea{min-height:7.5em;min-width:15em}label{display:inline-block}fieldset>*,figure img{display:block}input,select{display:inline}fieldset>*,form>:not(fieldset){margin-right:.75em}button,input[type=reset],input[type=submit]{background:var(--primary);color:var(--text-color);cursor:pointer;display:inline-block;padding:.75em 1.5em;text-align:center;margin:0 .75em 1.5em 0}button:hover,input[type=reset]:hover,input[type=submit]:hover{background:var(--primary-dark);color:var(--text-color)}button[disabled],input[type=reset][disabled],input[type=submit][disabled]{background:#e6e6e6;color:#404040;cursor:not-allowed}button:not([disabled]),button[type=submit],input[type=submit]{background:#f9c412;color:#181818}button:not([disabled]):hover,button[type=submit]:hover,input[type=submit]:hover{background:#ba9005;color:#000;background:var(--primary-dark)}input[type=color],input[type=date],input[type=datetime-local],input[type=datetime],input[type=email],input[type=file],input[type=month],input[type=number],input[type=password],input[type=phone],input[type=range],input[type=search],input[type=tel],input[type=text],input[type=time],input[type=url],input[type=week],select,textarea{border:1px solid #595959;padding:.75em}input[type=checkbox],input[type=radio]{flex-grow:0;margin:.75em .375em .75em 0;vertical-align:middle}input[type=checkbox]+label,input[type=radio]+label{page-break-before:avoid}select[multiple]{min-width:15em}*{border:0;box-sizing:border-box}article,img,video{max-width:100%;margin:0 auto}img,video{height:auto}body{font-family:var(--font-family);background:var(--bg-color);color:var(--text-color)}section{margin-left:auto;margin-right:auto;width:900px}main{max-width:70rem;margin:0 auto}footer{background:var(--footer-bg-color);padding:1em;text-align:center;border-top:.5px solid #d3d3d3}footer,footer a{color:var(--footer-text-color)}footer>*{font-family:'Oswald'}footer nav a img{vertical-align:middle}footer nav,footer p{font-size:90%}article{padding:0 1.5em 4.5em;width:45.5em;min-height:100vh}ol,ul{margin-top:0}li dl,li ol,li ul{margin-bottom:0}dt{padding-top:.75em;padding-left:.75em}dd{padding-bottom:.75em;margin-left:2.25em}dd+dt{border-top:1px solid #f9c412;border-top:1px solid var(--primary)}blockquote{border-left:1px solid #f9c412;padding:0 1.5em;margin:1.5em 0 1.5em 1.5em;border-left:3px solid var(--primary)}blockquote footer{background:0;display:block;color:#ccc;padding:.75em 0;font-size:90%;text-align:start}figure,footer>*{margin:1.5em}code[class*=language-],pre[class*=language-]{color:#ccc;background:0;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-]{padding:0}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#2d2d2d}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.block-comment,.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#999}.token.punctuation{color:#ccc}.token.attr-name,.token.deleted,.token.namespace,.token.tag{color:#e2777a}.token.function-name{color:#6196cc}.token.boolean,.token.function,.token.number{color:#f08d49}.token.class-name,.token.constant,.token.property,.token.symbol{color:#f8c555}.token.atrule,.token.builtin,.token.important,.token.keyword,.token.selector{color:#cc99cd}.token.attr-value,.token.char,.token.regex,.token.string,.token.variable{color:#7ec699}.token.entity,.token.operator,.token.url{color:#67cdcc}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.token.inserted{color:green}button:not([disabled]),button[type=submit],input[type=submit]{background:var(--primary)}::-webkit-scrollbar-thumb:hover{background:var(--primary)}.about{min-height:80vh}.about h1,.tags-list h1{font-family:'Coustard';padding-bottom:1em}.tags-list{text-align:center}.tags,.tags-list{min-height:80vh}.tags h1,article h1{text-align:center;padding-bottom:1em}.tags h1,article h1,article h2,h3,h4,h5,h6{font-family:'Coustard'}@media (min-width:600px){.about{min-height:calc(100vh - 360px)}.tags-list{text-align:center}.tags,.tags-list{min-height:calc(100vh - 360px)}}.home .banner{width:100%;margin-bottom:3em;opacity:90%}.post{margin-bottom:30px}.post .title,article h1,article h2,h3,h4,h5,h6{color:var(--heading-color)}.post .title{font-family:"Coustard";font-size:1.125em}.post .title .draft{color:#b8860b}.post .date,.post .description{margin-top:5px;color:var(--text-color)}.post .date{font-size:.75em;color:var(--post-date);text-transform:uppercase}.post .separator{color:var(--post-separator);opacity:.1}blockquote>p{font-size:1.5rem;font-style:italic}blockquote p:last-child{font-size:1.2rem;font-weight:400}header div{padding-bottom:4em}.pagetitle{font-family:"UnifrakturMaguntia";font-size:3em;font-weight:900}.menu,.pagetitle,.pagetitle:hover{text-decoration:none}nav{width:100%}#nav{max-width:45.5em;margin:0 auto;padding:.5em;display:flex;justify-content:center;gap:5px;border-top:1px solid #d3d3d3;border-bottom:1px solid #d3d3d3}.menu{padding:5px 10px;font-family:"Coustard"}share-widget div{width:20px;height:20px;background-image:url(/img/share.svg);background-repeat:no-repeat;background-position:center;color:gray}share-widget button{margin:0;background-color:#a9a9a9!important}share-widget button:hover{background-color:#ecbb19!important}share-widget button:active{transform:scale(1.2)}</style><header><div><a href=/ class=pagetitle title=Homepage>The Fortune Days</a></div><nav><div id=nav><a href=/ class=menu>Home</a> <a href=/tags/ class=menu>Tags</a> <a href=/about/ class=menu>About</a></div></nav><dialog id=message></dialog></header><main><article><h1>Apache Spark Structured Streaming</h1><p>In this blog post, we're going to explore features of Apache Spark Structured Streaming by building an application that read structured data from Kafka and then streaming it into PostgresSQL.<p>This blog post is the next session of the previous <a href=/articles/getting-started-with-apache-spark/ >Getting Started With Apache Spark</a>, hence please visit that post for basic setup as we will not repeat them here.<p>Note that we will use <code>spark-operator</code> to deploy our Spark application, hence please make sure you installed the spark-operator accordingly. If you have not done it yet, take a look at it <a href=https://thefortunedays.com/articles/getting-started-with-apache-spark/#deploy-using-spark-operator>here</a><p>Please notice that this blog post's purpose is to provide steps for those who want to try with Spark streaming, it's not a comprehensive tutorial. If you expect a comprehensive tutorial please visit Apache Spark guideline.<h2 id=prerequisite>Prerequisite <a href=#prerequisite class=direct-link>#</a></h2><ul><li><a href=https://www.docker.com/ >Docker</a><li><a href=https://minikube.sigs.k8s.io/docs/ >Minikube</a><li><a href=https://thefortunedays.com/articles/getting-started-with-apache-spark/#deploy-kafka>Kafka</a>: with topic <code>test</code> created in advance.<li><a href=https://thefortunedays.com/articles/getting-started-with-apache-spark/#deploy-using-spark-operator>spark-operator</a></ul><h2 id=install-postgres>Install PostGres <a href=#install-postgres class=direct-link>#</a></h2><p>Install PostGres using bitnami helm chart:<pre class=language-shell><code class=language-shell>helm <span class="token function">install</span> postgresql oci://registry-1.docker.io/bitnamicharts/postgresql</code></pre><p>Connect to PostGres<pre class=language-shell><code class=language-shell><span class="token builtin class-name">export</span> <span class="token variable assign-left">POSTGRES_PASSWORD</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span>kubectl get secret --namespace default postgresql -o <span class="token variable assign-left">jsonpath</span><span class="token operator">=</span><span class="token string">"{.data.postgres-password}"</span> <span class="token operator">|</span> base64 -d<span class="token variable">)</span></span><br><br>kubectl run postgresql-client --rm --tty -i --restart<span class="token operator">=</span><span class="token string">'Never'</span> --namespace default --image docker.io/bitnami/postgresql:16.2.0-debian-12-r6 --env<span class="token operator">=</span><span class="token string">"PGPASSWORD=<span class="token variable">$POSTGRES_PASSWORD</span>"</span> <span class="token punctuation">\</span><br>      --command -- psql --host postgresql -U postgres -d postgres -p <span class="token number">5432</span><span class="token punctuation">;</span></code></pre><p>Create database and user:<pre class=language-sql><code class=language-sql><span class="token keyword">CREATE</span> <span class="token keyword">USER</span> spark <span class="token keyword">WITH</span> ENCRYPTED PASSWORD <span class="token string">'spark123'</span><span class="token punctuation">;</span><br><br><span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> spark <span class="token keyword">WITH</span> OWNER spark<span class="token punctuation">;</span><br><br>\<span class="token keyword">connect</span> spark<span class="token punctuation">;</span><br>\dt</code></pre><p>Create secret to store user/pass:<pre class=language-shell><code class=language-shell>kubectl create secret generic db-user-pass <span class="token punctuation">\</span><br>    --from-literal<span class="token operator">=</span>username<span class="token operator">=</span>spark <span class="token punctuation">\</span><br>    --from-literal<span class="token operator">=</span>password<span class="token operator">=</span><span class="token string">'spark123'</span></code></pre><h2 id=build-the-application>Build the application <a href=#build-the-application class=direct-link>#</a></h2><p><code>Main.scala</code><pre class=language-scala><code class=language-scala><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token punctuation">{</span>col<span class="token punctuation">,</span> from_json<span class="token punctuation">}</span><br><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span>StructType<br><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Dataset<span class="token punctuation">,</span> Encoders<span class="token punctuation">,</span> SaveMode<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span><br><br><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>Timestamp<br><br><br><br><span class="token keyword">object</span> Main <span class="token punctuation">{</span><br>  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span><br>    <span class="token keyword">val</span> spark<span class="token operator">:</span>SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"hello-spark-streaming"</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span><br><br>    <span class="token keyword">val</span> kafkaUser <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"KAFKA_USER"</span><span class="token punctuation">,</span> <span class="token string">"user1"</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> kafkaPass <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"KAFKA_PASS"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> kafkaOpts <span class="token operator">=</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><br>      <span class="token string">"kafka.bootstrap.servers"</span><span class="token operator">-></span> <span class="token string">"kafka:9092"</span><span class="token punctuation">,</span><br>      <span class="token string">"subscribe"</span><span class="token operator">-></span> <span class="token string">"test"</span><span class="token punctuation">,</span><br>      <span class="token string">"kafka.sasl.mechanism"</span><span class="token operator">-></span> <span class="token string">"PLAIN"</span><span class="token punctuation">,</span><br>      <span class="token string">"kafka.security.protocol"</span> <span class="token operator">-></span> <span class="token string">"SASL_PLAINTEXT"</span><span class="token punctuation">,</span><br>      <span class="token string">"kafka.sasl.jaas.config"</span><span class="token operator">-></span> <span class="token string-interpolation"><span class="token function id">s</span><span class="token string">"""org.apache.kafka.common.security.plain.PlainLoginModule required username="</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">kafkaUser</span></span><span class="token string">" password="</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">kafkaPass</span></span><span class="token string">";"""</span></span><span class="token punctuation">,</span><br>    <span class="token punctuation">)</span><br>    <span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_<br>    <span class="token keyword">val</span> df <span class="token operator">=</span> spark<br>      <span class="token punctuation">.</span>readStream<br>      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"kafka"</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>options<span class="token punctuation">(</span>kafkaOpts<span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>selectExpr<span class="token punctuation">(</span><span class="token string">"CAST(value as STRING) as value"</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>from_json<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Event<span class="token punctuation">.</span>schema<span class="token punctuation">)</span><span class="token punctuation">.</span>as<span class="token punctuation">[</span>Event<span class="token punctuation">]</span><span class="token punctuation">)</span><br><br>    <span class="token keyword">val</span> dbName <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"POSTGRESQL_DBNAME"</span><span class="token punctuation">,</span><span class="token string">"spark"</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> dbUser <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"POSTGRESQL_USER"</span><span class="token punctuation">,</span> <span class="token string">"spark"</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> dbPass <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"POSTGRESQL_PASS"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> postGreOpts <span class="token operator">=</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><br>      <span class="token string">"url"</span> <span class="token operator">-></span> <span class="token string-interpolation"><span class="token function id">s</span><span class="token string">"jdbc:postgresql://postgresql:5432/</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">dbName</span></span><span class="token string">"</span></span><span class="token punctuation">,</span><br>      <span class="token string">"driver"</span> <span class="token operator">-></span> <span class="token string">"org.postgresql.Driver"</span><span class="token punctuation">,</span><br>      <span class="token string">"user"</span> <span class="token operator">-></span> dbUser<span class="token punctuation">,</span><br>      <span class="token string">"password"</span> <span class="token operator">-></span> dbPass<span class="token punctuation">,</span><br>      <span class="token string">"dbtable"</span> <span class="token operator">-></span> <span class="token string">"events"</span><span class="token punctuation">,</span><br>    <span class="token punctuation">)</span><br>    df<span class="token punctuation">.</span>writeStream<br>      <span class="token punctuation">.</span>foreachBatch<span class="token punctuation">(</span><span class="token punctuation">(</span>batch <span class="token operator">:</span>Dataset<span class="token punctuation">[</span>Event<span class="token punctuation">]</span><span class="token punctuation">,</span> _<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">{</span><br>        batch<span class="token punctuation">.</span>write<br>          <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span><br>          <span class="token punctuation">.</span>options<span class="token punctuation">(</span>postGreOpts<span class="token punctuation">)</span><br>          <span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Overwrite<span class="token punctuation">)</span><br>          <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span><br>      <span class="token punctuation">}</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span><br>  <span class="token punctuation">}</span><br><span class="token punctuation">}</span><br><br><span class="token keyword">case</span> <span class="token keyword">class</span> Event<span class="token punctuation">(</span>uuid<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> typ<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> data<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> ts<span class="token operator">:</span> Timestamp<span class="token punctuation">)</span><br><br><span class="token keyword">object</span> Event <span class="token punctuation">{</span><br>  <span class="token keyword">val</span> schema<span class="token operator">:</span> StructType <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>product<span class="token punctuation">[</span>Event<span class="token punctuation">]</span><span class="token punctuation">.</span>schema<br><span class="token punctuation">}</span></code></pre><p><code>build.sbt</code><pre class=language-shell><code class=language-shell>ThisBuild / version :<span class="token operator">=</span> <span class="token string">"0.1.0-SNAPSHOT"</span><br><br>ThisBuild / scalaVersion :<span class="token operator">=</span> <span class="token string">"2.12.18"</span><br><br>libraryDependencies <span class="token operator">+=</span> <span class="token string">"org.apache.spark"</span> %% <span class="token string">"spark-core"</span> % <span class="token string">"3.5.1"</span><br>libraryDependencies <span class="token operator">+=</span> <span class="token string">"org.apache.spark"</span> %% <span class="token string">"spark-sql"</span> % <span class="token string">"3.5.1"</span><br>libraryDependencies <span class="token operator">+=</span> <span class="token string">"org.apache.spark"</span> %% <span class="token string">"spark-sql-kafka-0-10"</span> % <span class="token string">"3.5.1"</span> % Test<br>libraryDependencies <span class="token operator">+=</span> <span class="token string">"org.postgresql"</span> % <span class="token string">"postgresql"</span> % <span class="token string">"42.7.2"</span><br><br>Compile / run / mainClass :<span class="token operator">=</span> Some<span class="token punctuation">(</span><span class="token string">"Main"</span><span class="token punctuation">)</span><br><br>lazy val root <span class="token operator">=</span> <span class="token punctuation">(</span>project <span class="token keyword">in</span> file<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">))</span><br>  .settings<span class="token punctuation">(</span><br>    name :<span class="token operator">=</span> <span class="token string">"hello-spark"</span><br>  <span class="token punctuation">)</span><br></code></pre><p><code>Dockerfile</code><pre class=language-dockerfile><code class=language-dockerfile><span class="token instruction"><span class="token keyword">ARG</span> SCALA_VERSION=2.12</span><br><span class="token instruction"><span class="token keyword">ARG</span> ARG_JAR_NAME=hello-spark_2.12-0.1.0-SNAPSHOT.jar</span><br><span class="token instruction"><span class="token keyword">ARG</span> ARG_MAIN_CLASS=Main</span><br><br><span class="token instruction"><span class="token keyword">FROM</span> sbtscala/scala-sbt:graalvm-ce-22.3.3-b1-java17_1.9.9_2.12.18 <span class="token keyword">as</span> build</span><br><span class="token instruction"><span class="token keyword">WORKDIR</span> /app</span><br><span class="token instruction"><span class="token keyword">COPY</span> . .</span><br><span class="token instruction"><span class="token keyword">RUN</span> sbt package</span><br><br><span class="token instruction"><span class="token keyword">FROM</span> apache/spark:3.5.1-scala2.12-java17-ubuntu</span><br><span class="token instruction"><span class="token keyword">ARG</span> ARG_JAR_NAME</span><br><span class="token instruction"><span class="token keyword">ARG</span> ARG_MAIN_CLASS</span><br><span class="token instruction"><span class="token keyword">ARG</span> SCALA_VERSION</span><br><span class="token instruction"><span class="token keyword">COPY</span> <span class="token options"><span class="token property">--from</span><span class="token punctuation">=</span><span class="token string">build</span></span> /app/target/scala-<span class="token variable">${SCALA_VERSION}</span>/<span class="token variable">${ARG_JAR_NAME}</span> /app/work/application.jar</span></code></pre><p>Build Docker image:<pre class=language-shell><code class=language-shell><span class="token function">docker</span> build -t hello-spark-streaming:latest <span class="token builtin class-name">.</span></code></pre><p><code>spark-streaming-application.yaml</code><pre class=language-yaml><code class=language-yaml><span class="token atrule key">apiVersion</span><span class="token punctuation">:</span> sparkoperator.k8s.io/v1beta2<br><span class="token atrule key">kind</span><span class="token punctuation">:</span> SparkApplication<br><span class="token atrule key">metadata</span><span class="token punctuation">:</span><br>  <span class="token atrule key">name</span><span class="token punctuation">:</span> hello<span class="token punctuation">-</span>spark<span class="token punctuation">-</span>streaming<br>  <span class="token atrule key">namespace</span><span class="token punctuation">:</span> default<br><span class="token atrule key">spec</span><span class="token punctuation">:</span><br>  <span class="token atrule key">type</span><span class="token punctuation">:</span> Scala<br>  <span class="token atrule key">sparkVersion</span><span class="token punctuation">:</span> 3.5.1<br>  <span class="token atrule key">mode</span><span class="token punctuation">:</span> cluster<br>  <span class="token atrule key">image</span><span class="token punctuation">:</span> hello<span class="token punctuation">-</span>spark<span class="token punctuation">-</span>streaming<span class="token punctuation">:</span>latest<br>  <span class="token atrule key">mainClass</span><span class="token punctuation">:</span> Main<br>  <span class="token atrule key">mainApplicationFile</span><span class="token punctuation">:</span> local<span class="token punctuation">:</span>///app/work/application.jar<br>  <span class="token atrule key">deps</span><span class="token punctuation">:</span><br>    <span class="token atrule key">packages</span><span class="token punctuation">:</span><br>      <span class="token punctuation">-</span> org.apache.spark<span class="token punctuation">:</span>spark<span class="token punctuation">-</span>sql<span class="token punctuation">-</span>kafka<span class="token punctuation">-</span>0<span class="token punctuation">-</span>10_2.12<span class="token punctuation">:</span>3.5.1<br>      <span class="token punctuation">-</span> org.postgresql<span class="token punctuation">:</span>postgresql<span class="token punctuation">:</span>42.7.2<br>  <span class="token atrule key">sparkConf</span><span class="token punctuation">:</span><br>    <span class="token atrule key">"spark.driver.extraJavaOptions"</span><span class="token punctuation">:</span> <span class="token string">"-Divy.cache.dir=/tmp -Divy.home=/tmp"</span><br>  <span class="token atrule key">driver</span><span class="token punctuation">:</span><br>    <span class="token atrule key">memory</span><span class="token punctuation">:</span> 512m<br>    <span class="token atrule key">labels</span><span class="token punctuation">:</span><br>      <span class="token atrule key">version</span><span class="token punctuation">:</span> 3.5.1<br>    <span class="token atrule key">serviceAccount</span><span class="token punctuation">:</span> sparksubmit<br>    <span class="token atrule key">env</span><span class="token punctuation">:</span><br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> KAFKA_USER<br>        <span class="token atrule key">value</span><span class="token punctuation">:</span> user1<br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> KAFKA_PASS<br>        <span class="token atrule key">valueFrom</span><span class="token punctuation">:</span><br>          <span class="token atrule key">secretKeyRef</span><span class="token punctuation">:</span><br>            <span class="token atrule key">name</span><span class="token punctuation">:</span> kafka<span class="token punctuation">-</span>user<span class="token punctuation">-</span>passwords<br>            <span class="token atrule key">key</span><span class="token punctuation">:</span> client<span class="token punctuation">-</span>passwords<br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> POSTGRESQL_DBNAME<br>        <span class="token atrule key">value</span><span class="token punctuation">:</span> spark<br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> POSTGRESQL_USER<br>        <span class="token atrule key">valueFrom</span><span class="token punctuation">:</span><br>          <span class="token atrule key">secretKeyRef</span><span class="token punctuation">:</span><br>            <span class="token atrule key">name</span><span class="token punctuation">:</span> db<span class="token punctuation">-</span>user<span class="token punctuation">-</span>pass<br>            <span class="token atrule key">key</span><span class="token punctuation">:</span> username<br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> POSTGRESQL_PASS<br>        <span class="token atrule key">valueFrom</span><span class="token punctuation">:</span><br>          <span class="token atrule key">secretKeyRef</span><span class="token punctuation">:</span><br>            <span class="token atrule key">name</span><span class="token punctuation">:</span> db<span class="token punctuation">-</span>user<span class="token punctuation">-</span>pass<br>            <span class="token atrule key">key</span><span class="token punctuation">:</span> password<br>  <span class="token atrule key">executor</span><span class="token punctuation">:</span><br>    <span class="token atrule key">memory</span><span class="token punctuation">:</span> 512m<br>    <span class="token atrule key">instances</span><span class="token punctuation">:</span> <span class="token number">3</span><br>    <span class="token atrule key">labels</span><span class="token punctuation">:</span><br>      <span class="token atrule key">version</span><span class="token punctuation">:</span> 3.5.1</code></pre><p>Deploy the application:<pre class=language-shell><code class=language-shell>kubectl apply -f spark-streaming-application.yaml</code></pre><p>Check status:<pre class=language-shell><code class=language-shell>kubectl get pod<br>NAME                                            READY   STATUS    RESTARTS       AGE<br>hello-spark-streaming-86b6a38e376d2a19-exec-1   <span class="token number">1</span>/1     Running   <span class="token number">0</span>              3m33s<br>hello-spark-streaming-86b6a38e376d2a19-exec-2   <span class="token number">1</span>/1     Running   <span class="token number">0</span>              3m33s<br>hello-spark-streaming-86b6a38e376d2a19-exec-3   <span class="token number">1</span>/1     Running   <span class="token number">0</span>              3m33s<br>hello-spark-streaming-driver                    <span class="token number">1</span>/1     Running   <span class="token number">0</span>              6m9s<br>kafka-client                                    <span class="token number">1</span>/1     Running   <span class="token number">0</span>              133m<br>kafka-controller-0                              <span class="token number">1</span>/1     Running   <span class="token number">1</span> <span class="token punctuation">(</span>161m ago<span class="token punctuation">)</span>   6h15m<br>kafka-controller-1                              <span class="token number">1</span>/1     Running   <span class="token number">1</span> <span class="token punctuation">(</span>161m ago<span class="token punctuation">)</span>   6h15m<br>kafka-controller-2                              <span class="token number">1</span>/1     Running   <span class="token number">1</span> <span class="token punctuation">(</span>161m ago<span class="token punctuation">)</span>   6h15m<br>postgresql-0                                    <span class="token number">1</span>/1     Running   <span class="token number">0</span>              84m<br>postgresql-client                               <span class="token number">1</span>/1     Running   <span class="token number">0</span>              27m</code></pre><p>Produce some messages:<pre class=language-shell><code class=language-shell>kafka-console-producer.sh --topic <span class="token builtin class-name">test</span> --request-required-acks all --bootstrap-server kafka:9092 --producer.config client.conf<br><br><span class="token punctuation">{</span><span class="token string">"uuid"</span><span class="token builtin class-name">:</span><span class="token string">"f7a66f45-a671-4bf7-97af-cb58fffdbd54"</span>, <span class="token string">"typ"</span><span class="token builtin class-name">:</span> <span class="token string">"setup"</span>, <span class="token string">"data"</span><span class="token builtin class-name">:</span><span class="token string">"event 1"</span>, <span class="token string">"ts"</span><span class="token builtin class-name">:</span><span class="token string">"2024-03-11 09:09:45.847317+00"</span><span class="token punctuation">}</span></code></pre><p>Check data in postgres:<pre class=language-sql><code class=language-sql><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> events<span class="token punctuation">;</span></code></pre><share-widget><button aria-label=Share href=https://thefortunedays.com/articles/getting-started-with-apache-spark-structured-streaming-kafka-postgresql/ on-click=share><div></div></button></share-widget><script type=application/ld+json>{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Apache Spark Structured Streaming",
  "image": [],
  "author": "Thanh", 
  "genre": "Blog", 
  "publisher": {
    "@type": "Organization",
    "name": "Thanh",
    "logo": {
      "@type": "ImageObject",
      "url": "/img/favicon/favicon-192x192.png?hash=735479e2c4"
    }
  },
  "url": "https://thefortunedays.com/articles/getting-started-with-apache-spark-structured-streaming-kafka-postgresql/",
  "mainEntityOfPage": "https://thefortunedays.com/articles/getting-started-with-apache-spark-structured-streaming-kafka-postgresql/",
  "datePublished": "2024-03-11",
  "dateModified": "2024-10-28",
  "description": "In this blog post, we&#39;re going to explore features of Apache Spark Structured Streaming by building an application that read structured data..."
}</script></article></main><footer><a href=/about/ >Thanh</a></footer>