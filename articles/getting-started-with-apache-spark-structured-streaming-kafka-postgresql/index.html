<!DOCTYPE html><html domain=thefortunedays.com lang=en><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><link href=/favicon.svg rel=icon type=image/svg+xml><meta content=#ff577d name=theme-color><meta content="max-snippet:-1, max-image-preview: large, max-video-preview: -1" name=robots><title>Apache Spark Structured Streaming</title><meta content="Apache Spark Structured Streaming" property=og:title><meta content="Getting started with Apache Spark and Structure Streaming on Kubernetes." name=description><meta content="Getting started with Apache Spark and Structure Streaming on Kubernetes." property=og:description><meta content=summary_large_image name=twitter:card><meta content=@phamthethanh108 name=twitter:site><meta content=@phamthethanh108 name=twitter:creator><meta content=https://thefortunedays.com/img/remote/Z1o6V9l.jpg property=og:image><link href=https://thefortunedays.com/articles/getting-started-with-apache-spark-structured-streaming-kafka-postgresql/ rel=canonical><meta content=no-referrer-when-downgrade name=referrer><link href=/feed/feed.xml rel=alternate type=application/atom+xml title="The Fortune Days"><link href=/ rel=preconnect crossorigin=""><link href=/fonts/CyberwayRiders.woff2 rel=preload crossorigin="" as=font type=font/woff2><link href=https://fonts.googleapis.com rel=preconnect><link href=https://fonts.gstatic.com rel=preconnect crossorigin=""><link href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap" rel=stylesheet><script async data-cwv-src="/js/web-vitals.js?hash=4a3c7b61e1" defer src="/js/min.js?hash=8db32dcb3a"></script><script csp-hash="">if (/Mac OS X/.test(navigator.userAgent))document.documentElement.classList.add('apple')</script><style>:root{--primary: #ff577d;--text-color: #f5f5f7;--bg-color: #003062;--nav-bg-color: #ff577d;--nav-text-color: #fff;--nav-text-shadow: #0a9cf5;--reading-progress: #ff184c;--footer-bg-color: #091833;--footer-text-color: #999;--footer-text-shadow: #0a9cf5;--heading-text-shadow: #0a9cf5;--main-width: calc(100vw - 3em)
}main img{content-visibility:auto}article *{scroll-margin-top:50px}header nav{position:fixed;padding:.575em 1.5em;background:var(--nav-bg-color);color:var(--nav-text-color);font-weight:200;text-align:right}@media (min-width:37.5em){:root{--main-width: calc(37.5em - 3em)
  }}dialog,share-widget{position:fixed;opacity:.9}share-widget{right:20px;bottom:20px}share-widget div{width:20px;height:20px;background-image:url(/img/share.svg);background-repeat:no-repeat;background-position:center}.apple share-widget div{background-image:url(/img/share-apple.svg)}body,share-widget button{margin:0}share-widget button:active{transform:scale(1.2)}dialog{background-color:#0a9cf5;z-index:1000}#nav{z-index:2;position:relative}#reading-progress,header nav{z-index:1;width:100vw;left:0;top:0}#reading-progress{background-color:var(--reading-progress);position:absolute;bottom:0;transform:translate(-100vw,0);will-change:transform;pointer-events:none}@font-face{font-display:optional;font-family:CyberwayRiders;font-weight:100 900;font-style:oblique 0deg 10deg;src:url(/fonts/CyberwayRiders.woff2) format("woff2");font-display:swap}html{line-height:1.15;-webkit-text-size-adjust:100%;font-size:17.5px}@media (max-width:768px){html{font-size:14px}}pre{font-size:1em}a{background-color:transparent;color:#f9c412;text-decoration:none;color:var(--primary)}img{border-style:none;max-width:100%;height:auto;margin:0 auto}button,select{font-family:inherit;font-size:100%;line-height:1.15;text-transform:none}button{overflow:visible}select{margin:0}[type=button],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}h1,h2{margin:3rem 0 1.38rem;line-height:1.3}h1{font-size:2.488rem}h2{font-size:2.074rem}body,p,pre,ul{font-size:1rem;line-height:1.6}p,pre,ul{margin-bottom:1.36rem}code,pre{overflow-x:auto}pre{font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace}pre:has(code:not([class])){background:#2d2d2d}pre code:not([class]){color:#ccc;padding:0;overflow-x:scroll}code{border-radius:.3em;color:var(--code);padding:0 .3em;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:90%;background:var(--code-bg)}h1,h2{font-family:var(--font-family)}a:hover{text-decoration:underline}dt{font-weight:600;padding-top:.75em;padding-left:.75em}html{font-family:Montserrat,sans-serif;--font-family: "Montserrat", sans-serif
}button,select{border-radius:.3em;max-width:100%}select{margin-bottom:1.5em;display:inline;border:1px solid #595959;padding:.75em}button,button:hover{color:var(--text-color)}button{background:var(--primary);cursor:pointer;display:inline-block;padding:.75em 1.5em;text-align:center;margin:0 .75em 1.5em 0}button:hover{background:var(--primary-dark)}button:not([disabled]){background:#f9c412;color:#181818;background:var(--primary)}button:not([disabled]):hover{background:#ba9005;color:#000;background:var(--primary-dark)}*{border:0;box-sizing:border-box}body,header nav a{font-family:var(--font-family)}body{background:var(--bg-color);color:var(--text-color)}header{padding:4em 1.5em 3em;width:37.5em;margin:0 auto;text-align:center;max-width:100%;display:flex;align-items:center;flex-direction:column}header p,ul{margin-top:0}header nav h1{float:left;font-size:inherit;line-height:inherit;margin:0;text-align:left}header nav a{font-weight:700;text-decoration:none;color:var(--nav-text-color);margin-left:1.5em;font-family:CyberwayRiders;text-shadow:0 0 7px #fff,0 0 42px var(--nav-text-shadow)}header nav a:first-of-type{margin-left:auto}header nav a:last-of-type{margin-right:1.5em}main{max-width:70rem;margin:0 auto}footer{background:var(--footer-bg-color);color:var(--footer-text-color);padding:3em;text-align:center}footer>*{margin:1.5em;font-family:CyberwayRiders;text-shadow:0 0 7px #fff,0 0 42px var(--footer-text-shadow)}footer nav a img{vertical-align:middle}footer nav,footer p{font-size:90%}article{max-width:100%;padding:0 1.5em;width:37.5em;margin:0 auto;min-height:100vh}li ul{margin-bottom:0}code[class*=language-],pre[class*=language-]{color:#ccc;background:0;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-]{padding:0}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#2d2d2d}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.comment{color:#999}.token.punctuation{color:#ccc}.token.namespace{color:#e2777a}.token.function,.token.number{color:#f08d49}.token.class-name,.token.property{color:#f8c555}.token.atrule,.token.builtin,.token.keyword{color:#cc99cd}.token.string,.token.variable{color:#7ec699}.token.operator,.token.url{color:#67cdcc}.token.inserted{color:green}.about,.tags{min-height:80vh}.about h1{padding-bottom:1em}.about h1,.tags h1,article h1,article h2{font-family:CyberwayRiders}article h1,article h2{color:#fff}.tags h1,article h1{text-align:center;padding-bottom:1em}article h1{text-shadow:0 0 7px #fff,0 0 10px #fff,0 0 21px #fff,0 0 42px var(--heading-text-shadow),0 0 82px var(--heading-text-shadow),0 0 92px var(--heading-text-shadow)}article h2{text-shadow:0 0 7px #fff,0 0 10px #fff,0 0 21px #fff,0 0 42px var(--heading-text-shadow),0 0 82px var(--heading-text-shadow)}@media (min-width:600px){.about,.tags{min-height:calc(100vh - 360px)}}.post{margin-bottom:30px}.post .title{font-weight:700;color:var(--primary)}.post .description{margin-top:5px;color:var(--text-color)}</style><header><nav><div id=nav><h1><a href=/ title=Homepage>The Fortune Days</a></h1><a href=/tags/ >Tags</a> <a href=/about/ >About</a></div><div id=reading-progress aria-hidden=true></div></nav><dialog id=message></dialog></header><main><article><h1>Apache Spark Structured Streaming</h1><p>In this blog post, we're going to explore features of Apache Spark Structured Streaming by building an application that read structured data from Kafka and then streaming it into PostgresSQL.<p>This blog post is the next session of the previous <a href=/articles/getting-started-with-apache-spark/ >Getting Started With Apache Spark</a>, hence please visit that post for basic setup as we will not repeat them here.<p>Note that we will use <code>spark-operator</code> to deploy our Spark application, hence please make sure you installed the spark-operator accordingly. If you have not done it yet, take a look at it <a href=https://thefortunedays.com/articles/getting-started-with-apache-spark/#deploy-using-spark-operator>here</a><p>Please notice that this blog post's purpose is to provide steps for those who want to try with Spark streaming, it's not a comprehensive tutorial. If you expect a comprehensive tutorial please visit Apache Spark guideline.<h2 id=prerequisite>Prerequisite <a href=#prerequisite class=direct-link>#</a></h2><ul><li><a href=https://www.docker.com/ >Docker</a><li><a href=https://minikube.sigs.k8s.io/docs/ >Minikube</a><li><a href=https://thefortunedays.com/articles/getting-started-with-apache-spark/#deploy-kafka>Kafka</a>: with topic <code>test</code> created in advance.<li><a href=https://thefortunedays.com/articles/getting-started-with-apache-spark/#deploy-using-spark-operator>spark-operator</a></ul><h2 id=install-postgres>Install PostGres <a href=#install-postgres class=direct-link>#</a></h2><p>Install PostGres using bitnami helm chart:<pre class=language-shell><code class=language-shell>helm <span class="token function">install</span> postgresql oci://registry-1.docker.io/bitnamicharts/postgresql</code></pre><p>Connect to PostGres<pre class=language-shell><code class=language-shell><span class="token builtin class-name">export</span> <span class="token variable assign-left">POSTGRES_PASSWORD</span><span class="token operator">=</span><span class="token variable"><span class="token variable">$(</span>kubectl get secret --namespace default postgresql -o <span class="token variable assign-left">jsonpath</span><span class="token operator">=</span><span class="token string">"{.data.postgres-password}"</span> <span class="token operator">|</span> base64 -d<span class="token variable">)</span></span><br><br>kubectl run postgresql-client --rm --tty -i --restart<span class="token operator">=</span><span class="token string">'Never'</span> --namespace default --image docker.io/bitnami/postgresql:16.2.0-debian-12-r6 --env<span class="token operator">=</span><span class="token string">"PGPASSWORD=<span class="token variable">$POSTGRES_PASSWORD</span>"</span> <span class="token punctuation">\</span><br>      --command -- psql --host postgresql -U postgres -d postgres -p <span class="token number">5432</span><span class="token punctuation">;</span></code></pre><p>Create database and user:<pre class=language-sql><code class=language-sql><span class="token keyword">CREATE</span> <span class="token keyword">USER</span> spark <span class="token keyword">WITH</span> ENCRYPTED PASSWORD <span class="token string">'spark123'</span><span class="token punctuation">;</span><br><br><span class="token keyword">CREATE</span> <span class="token keyword">DATABASE</span> spark <span class="token keyword">WITH</span> OWNER spark<span class="token punctuation">;</span><br><br>\<span class="token keyword">connect</span> spark<span class="token punctuation">;</span><br>\dt</code></pre><p>Create secret to store user/pass:<pre class=language-shell><code class=language-shell>kubectl create secret generic db-user-pass <span class="token punctuation">\</span><br>    --from-literal<span class="token operator">=</span>username<span class="token operator">=</span>spark <span class="token punctuation">\</span><br>    --from-literal<span class="token operator">=</span>password<span class="token operator">=</span><span class="token string">'spark123'</span></code></pre><h2 id=build-the-application>Build the application <a href=#build-the-application class=direct-link>#</a></h2><p><code>Main.scala</code><pre class=language-scala><code class=language-scala><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>functions<span class="token punctuation">.</span></span><span class="token punctuation">{</span>col<span class="token punctuation">,</span> from_json<span class="token punctuation">}</span><br><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span>types<span class="token punctuation">.</span></span>StructType<br><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span><span class="token punctuation">{</span>Dataset<span class="token punctuation">,</span> Encoders<span class="token punctuation">,</span> SaveMode<span class="token punctuation">,</span> SparkSession<span class="token punctuation">}</span><br><br><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>sql<span class="token punctuation">.</span></span>Timestamp<br><br><br><br><span class="token keyword">object</span> Main <span class="token punctuation">{</span><br>  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">{</span><br>    <span class="token keyword">val</span> spark<span class="token operator">:</span>SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>appName<span class="token punctuation">(</span><span class="token string">"hello-spark-streaming"</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span><br><br>    <span class="token keyword">val</span> kafkaUser <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"KAFKA_USER"</span><span class="token punctuation">,</span> <span class="token string">"user1"</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> kafkaPass <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"KAFKA_PASS"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> kafkaOpts <span class="token operator">=</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><br>      <span class="token string">"kafka.bootstrap.servers"</span><span class="token operator">-></span> <span class="token string">"kafka:9092"</span><span class="token punctuation">,</span><br>      <span class="token string">"subscribe"</span><span class="token operator">-></span> <span class="token string">"test"</span><span class="token punctuation">,</span><br>      <span class="token string">"kafka.sasl.mechanism"</span><span class="token operator">-></span> <span class="token string">"PLAIN"</span><span class="token punctuation">,</span><br>      <span class="token string">"kafka.security.protocol"</span> <span class="token operator">-></span> <span class="token string">"SASL_PLAINTEXT"</span><span class="token punctuation">,</span><br>      <span class="token string">"kafka.sasl.jaas.config"</span><span class="token operator">-></span> <span class="token string-interpolation"><span class="token function id">s</span><span class="token string">"""org.apache.kafka.common.security.plain.PlainLoginModule required username="</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">kafkaUser</span></span><span class="token string">" password="</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">kafkaPass</span></span><span class="token string">";"""</span></span><span class="token punctuation">,</span><br>    <span class="token punctuation">)</span><br>    <span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_<br>    <span class="token keyword">val</span> df <span class="token operator">=</span> spark<br>      <span class="token punctuation">.</span>readStream<br>      <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"kafka"</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>options<span class="token punctuation">(</span>kafkaOpts<span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>selectExpr<span class="token punctuation">(</span><span class="token string">"CAST(value as STRING) as value"</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>select<span class="token punctuation">(</span>from_json<span class="token punctuation">(</span>col<span class="token punctuation">(</span><span class="token string">"value"</span><span class="token punctuation">)</span><span class="token punctuation">,</span>Event<span class="token punctuation">.</span>schema<span class="token punctuation">)</span><span class="token punctuation">.</span>as<span class="token punctuation">[</span>Event<span class="token punctuation">]</span><span class="token punctuation">)</span><br><br>    <span class="token keyword">val</span> dbName <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"POSTGRESQL_DBNAME"</span><span class="token punctuation">,</span><span class="token string">"spark"</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> dbUser <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"POSTGRESQL_USER"</span><span class="token punctuation">,</span> <span class="token string">"spark"</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> dbPass <span class="token operator">=</span> sys<span class="token punctuation">.</span>env<span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span><span class="token string">"POSTGRESQL_PASS"</span><span class="token punctuation">,</span> <span class="token string">""</span><span class="token punctuation">)</span><br>    <span class="token keyword">val</span> postGreOpts <span class="token operator">=</span> Map<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">,</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">(</span><br>      <span class="token string">"url"</span> <span class="token operator">-></span> <span class="token string-interpolation"><span class="token function id">s</span><span class="token string">"jdbc:postgresql://postgresql:5432/</span><span class="token interpolation"><span class="token punctuation">$</span><span class="token expression">dbName</span></span><span class="token string">"</span></span><span class="token punctuation">,</span><br>      <span class="token string">"driver"</span> <span class="token operator">-></span> <span class="token string">"org.postgresql.Driver"</span><span class="token punctuation">,</span><br>      <span class="token string">"user"</span> <span class="token operator">-></span> dbUser<span class="token punctuation">,</span><br>      <span class="token string">"password"</span> <span class="token operator">-></span> dbPass<span class="token punctuation">,</span><br>      <span class="token string">"dbtable"</span> <span class="token operator">-></span> <span class="token string">"events"</span><span class="token punctuation">,</span><br>    <span class="token punctuation">)</span><br>    df<span class="token punctuation">.</span>writeStream<br>      <span class="token punctuation">.</span>foreachBatch<span class="token punctuation">(</span><span class="token punctuation">(</span>batch <span class="token operator">:</span>Dataset<span class="token punctuation">[</span>Event<span class="token punctuation">]</span><span class="token punctuation">,</span> _<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token punctuation">{</span><br>        batch<span class="token punctuation">.</span>write<br>          <span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span><br>          <span class="token punctuation">.</span>options<span class="token punctuation">(</span>postGreOpts<span class="token punctuation">)</span><br>          <span class="token punctuation">.</span>mode<span class="token punctuation">(</span>SaveMode<span class="token punctuation">.</span>Overwrite<span class="token punctuation">)</span><br>          <span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span><br>      <span class="token punctuation">}</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>start<span class="token punctuation">(</span><span class="token punctuation">)</span><br>      <span class="token punctuation">.</span>awaitTermination<span class="token punctuation">(</span><span class="token punctuation">)</span><br>  <span class="token punctuation">}</span><br><span class="token punctuation">}</span><br><br><span class="token keyword">case</span> <span class="token keyword">class</span> Event<span class="token punctuation">(</span>uuid<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> typ<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> data<span class="token operator">:</span> <span class="token builtin">String</span><span class="token punctuation">,</span> ts<span class="token operator">:</span> Timestamp<span class="token punctuation">)</span><br><br><span class="token keyword">object</span> Event <span class="token punctuation">{</span><br>  <span class="token keyword">val</span> schema<span class="token operator">:</span> StructType <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>product<span class="token punctuation">[</span>Event<span class="token punctuation">]</span><span class="token punctuation">.</span>schema<br><span class="token punctuation">}</span></code></pre><p><code>build.sbt</code><pre class=language-shell><code class=language-shell>ThisBuild / version :<span class="token operator">=</span> <span class="token string">"0.1.0-SNAPSHOT"</span><br><br>ThisBuild / scalaVersion :<span class="token operator">=</span> <span class="token string">"2.12.18"</span><br><br>libraryDependencies <span class="token operator">+=</span> <span class="token string">"org.apache.spark"</span> %% <span class="token string">"spark-core"</span> % <span class="token string">"3.5.1"</span><br>libraryDependencies <span class="token operator">+=</span> <span class="token string">"org.apache.spark"</span> %% <span class="token string">"spark-sql"</span> % <span class="token string">"3.5.1"</span><br>libraryDependencies <span class="token operator">+=</span> <span class="token string">"org.apache.spark"</span> %% <span class="token string">"spark-sql-kafka-0-10"</span> % <span class="token string">"3.5.1"</span> % Test<br>libraryDependencies <span class="token operator">+=</span> <span class="token string">"org.postgresql"</span> % <span class="token string">"postgresql"</span> % <span class="token string">"42.7.2"</span><br><br>Compile / run / mainClass :<span class="token operator">=</span> Some<span class="token punctuation">(</span><span class="token string">"Main"</span><span class="token punctuation">)</span><br><br>lazy val root <span class="token operator">=</span> <span class="token punctuation">(</span>project <span class="token keyword">in</span> file<span class="token punctuation">(</span><span class="token string">"."</span><span class="token punctuation">))</span><br>  .settings<span class="token punctuation">(</span><br>    name :<span class="token operator">=</span> <span class="token string">"hello-spark"</span><br>  <span class="token punctuation">)</span><br></code></pre><p><code>Dockerfile</code><pre class=language-dockerfile><code class=language-dockerfile><span class="token instruction"><span class="token keyword">ARG</span> SCALA_VERSION=2.12</span><br><span class="token instruction"><span class="token keyword">ARG</span> ARG_JAR_NAME=hello-spark_2.12-0.1.0-SNAPSHOT.jar</span><br><span class="token instruction"><span class="token keyword">ARG</span> ARG_MAIN_CLASS=Main</span><br><br><span class="token instruction"><span class="token keyword">FROM</span> sbtscala/scala-sbt:graalvm-ce-22.3.3-b1-java17_1.9.9_2.12.18 <span class="token keyword">as</span> build</span><br><span class="token instruction"><span class="token keyword">WORKDIR</span> /app</span><br><span class="token instruction"><span class="token keyword">COPY</span> . .</span><br><span class="token instruction"><span class="token keyword">RUN</span> sbt package</span><br><br><span class="token instruction"><span class="token keyword">FROM</span> apache/spark:3.5.1-scala2.12-java17-ubuntu</span><br><span class="token instruction"><span class="token keyword">ARG</span> ARG_JAR_NAME</span><br><span class="token instruction"><span class="token keyword">ARG</span> ARG_MAIN_CLASS</span><br><span class="token instruction"><span class="token keyword">ARG</span> SCALA_VERSION</span><br><span class="token instruction"><span class="token keyword">COPY</span> <span class="token options"><span class="token property">--from</span><span class="token punctuation">=</span><span class="token string">build</span></span> /app/target/scala-<span class="token variable">${SCALA_VERSION}</span>/<span class="token variable">${ARG_JAR_NAME}</span> /app/work/application.jar</span></code></pre><p>Build Docker image:<pre class=language-shell><code class=language-shell><span class="token function">docker</span> build -t hello-spark-streaming:latest <span class="token builtin class-name">.</span></code></pre><p><code>spark-streaming-application.yaml</code><pre class=language-yaml><code class=language-yaml><span class="token atrule key">apiVersion</span><span class="token punctuation">:</span> sparkoperator.k8s.io/v1beta2<br><span class="token atrule key">kind</span><span class="token punctuation">:</span> SparkApplication<br><span class="token atrule key">metadata</span><span class="token punctuation">:</span><br>  <span class="token atrule key">name</span><span class="token punctuation">:</span> hello<span class="token punctuation">-</span>spark<span class="token punctuation">-</span>streaming<br>  <span class="token atrule key">namespace</span><span class="token punctuation">:</span> default<br><span class="token atrule key">spec</span><span class="token punctuation">:</span><br>  <span class="token atrule key">type</span><span class="token punctuation">:</span> Scala<br>  <span class="token atrule key">sparkVersion</span><span class="token punctuation">:</span> 3.5.1<br>  <span class="token atrule key">mode</span><span class="token punctuation">:</span> cluster<br>  <span class="token atrule key">image</span><span class="token punctuation">:</span> hello<span class="token punctuation">-</span>spark<span class="token punctuation">-</span>streaming<span class="token punctuation">:</span>latest<br>  <span class="token atrule key">mainClass</span><span class="token punctuation">:</span> Main<br>  <span class="token atrule key">mainApplicationFile</span><span class="token punctuation">:</span> local<span class="token punctuation">:</span>///app/work/application.jar<br>  <span class="token atrule key">deps</span><span class="token punctuation">:</span><br>    <span class="token atrule key">packages</span><span class="token punctuation">:</span><br>      <span class="token punctuation">-</span> org.apache.spark<span class="token punctuation">:</span>spark<span class="token punctuation">-</span>sql<span class="token punctuation">-</span>kafka<span class="token punctuation">-</span>0<span class="token punctuation">-</span>10_2.12<span class="token punctuation">:</span>3.5.1<br>      <span class="token punctuation">-</span> org.postgresql<span class="token punctuation">:</span>postgresql<span class="token punctuation">:</span>42.7.2<br>  <span class="token atrule key">sparkConf</span><span class="token punctuation">:</span><br>    <span class="token atrule key">"spark.driver.extraJavaOptions"</span><span class="token punctuation">:</span> <span class="token string">"-Divy.cache.dir=/tmp -Divy.home=/tmp"</span><br>  <span class="token atrule key">driver</span><span class="token punctuation">:</span><br>    <span class="token atrule key">memory</span><span class="token punctuation">:</span> 512m<br>    <span class="token atrule key">labels</span><span class="token punctuation">:</span><br>      <span class="token atrule key">version</span><span class="token punctuation">:</span> 3.5.1<br>    <span class="token atrule key">serviceAccount</span><span class="token punctuation">:</span> sparksubmit<br>    <span class="token atrule key">env</span><span class="token punctuation">:</span><br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> KAFKA_USER<br>        <span class="token atrule key">value</span><span class="token punctuation">:</span> user1<br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> KAFKA_PASS<br>        <span class="token atrule key">valueFrom</span><span class="token punctuation">:</span><br>          <span class="token atrule key">secretKeyRef</span><span class="token punctuation">:</span><br>            <span class="token atrule key">name</span><span class="token punctuation">:</span> kafka<span class="token punctuation">-</span>user<span class="token punctuation">-</span>passwords<br>            <span class="token atrule key">key</span><span class="token punctuation">:</span> client<span class="token punctuation">-</span>passwords<br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> POSTGRESQL_DBNAME<br>        <span class="token atrule key">value</span><span class="token punctuation">:</span> spark<br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> POSTGRESQL_USER<br>        <span class="token atrule key">valueFrom</span><span class="token punctuation">:</span><br>          <span class="token atrule key">secretKeyRef</span><span class="token punctuation">:</span><br>            <span class="token atrule key">name</span><span class="token punctuation">:</span> db<span class="token punctuation">-</span>user<span class="token punctuation">-</span>pass<br>            <span class="token atrule key">key</span><span class="token punctuation">:</span> username<br>      <span class="token punctuation">-</span> <span class="token atrule key">name</span><span class="token punctuation">:</span> POSTGRESQL_PASS<br>        <span class="token atrule key">valueFrom</span><span class="token punctuation">:</span><br>          <span class="token atrule key">secretKeyRef</span><span class="token punctuation">:</span><br>            <span class="token atrule key">name</span><span class="token punctuation">:</span> db<span class="token punctuation">-</span>user<span class="token punctuation">-</span>pass<br>            <span class="token atrule key">key</span><span class="token punctuation">:</span> password<br>  <span class="token atrule key">executor</span><span class="token punctuation">:</span><br>    <span class="token atrule key">memory</span><span class="token punctuation">:</span> 512m<br>    <span class="token atrule key">instances</span><span class="token punctuation">:</span> <span class="token number">3</span><br>    <span class="token atrule key">labels</span><span class="token punctuation">:</span><br>      <span class="token atrule key">version</span><span class="token punctuation">:</span> 3.5.1</code></pre><p>Deploy the application:<pre class=language-shell><code class=language-shell>kubectl apply -f spark-streaming-application.yaml</code></pre><p>Check status:<pre class=language-shell><code class=language-shell>kubectl get pod<br>NAME                                            READY   STATUS    RESTARTS       AGE<br>hello-spark-streaming-86b6a38e376d2a19-exec-1   <span class="token number">1</span>/1     Running   <span class="token number">0</span>              3m33s<br>hello-spark-streaming-86b6a38e376d2a19-exec-2   <span class="token number">1</span>/1     Running   <span class="token number">0</span>              3m33s<br>hello-spark-streaming-86b6a38e376d2a19-exec-3   <span class="token number">1</span>/1     Running   <span class="token number">0</span>              3m33s<br>hello-spark-streaming-driver                    <span class="token number">1</span>/1     Running   <span class="token number">0</span>              6m9s<br>kafka-client                                    <span class="token number">1</span>/1     Running   <span class="token number">0</span>              133m<br>kafka-controller-0                              <span class="token number">1</span>/1     Running   <span class="token number">1</span> <span class="token punctuation">(</span>161m ago<span class="token punctuation">)</span>   6h15m<br>kafka-controller-1                              <span class="token number">1</span>/1     Running   <span class="token number">1</span> <span class="token punctuation">(</span>161m ago<span class="token punctuation">)</span>   6h15m<br>kafka-controller-2                              <span class="token number">1</span>/1     Running   <span class="token number">1</span> <span class="token punctuation">(</span>161m ago<span class="token punctuation">)</span>   6h15m<br>postgresql-0                                    <span class="token number">1</span>/1     Running   <span class="token number">0</span>              84m<br>postgresql-client                               <span class="token number">1</span>/1     Running   <span class="token number">0</span>              27m</code></pre><p>Produce some messages:<pre class=language-shell><code class=language-shell>kafka-console-producer.sh --topic <span class="token builtin class-name">test</span> --request-required-acks all --bootstrap-server kafka:9092 --producer.config client.conf<br><br><span class="token punctuation">{</span><span class="token string">"uuid"</span><span class="token builtin class-name">:</span><span class="token string">"f7a66f45-a671-4bf7-97af-cb58fffdbd54"</span>, <span class="token string">"typ"</span><span class="token builtin class-name">:</span> <span class="token string">"setup"</span>, <span class="token string">"data"</span><span class="token builtin class-name">:</span><span class="token string">"event 1"</span>, <span class="token string">"ts"</span><span class="token builtin class-name">:</span><span class="token string">"2024-03-11 09:09:45.847317+00"</span><span class="token punctuation">}</span></code></pre><p>Check data in postgres:<pre class=language-sql><code class=language-sql><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> events<span class="token punctuation">;</span></code></pre><share-widget><button aria-label=Share href=https://thefortunedays.com/articles/getting-started-with-apache-spark-structured-streaming-kafka-postgresql/ on-click=share><div></div></button></share-widget><script type=application/ld+json>{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Apache Spark Structured Streaming",
  "image": [],
  "author": "Thanh", 
  "genre": "Blog", 
  "publisher": {
    "@type": "Organization",
    "name": "Thanh",
    "logo": {
      "@type": "ImageObject",
      "url": "/img/favicon/favicon-192x192.png?hash=735479e2c4"
    }
  },
  "url": "https://thefortunedays.com/articles/getting-started-with-apache-spark-structured-streaming-kafka-postgresql/",
  "mainEntityOfPage": "https://thefortunedays.com/articles/getting-started-with-apache-spark-structured-streaming-kafka-postgresql/",
  "datePublished": "2024-03-11",
  "dateModified": "2024-09-27",
  "description": "In this blog post, we&#39;re going to explore features of Apache Spark Structured Streaming by building an application that read structured data..."
}</script></article></main><footer><a href=/about/ >Thanh</a></footer>